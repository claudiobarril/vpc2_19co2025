{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T19:05:23.095389Z",
     "start_time": "2025-07-26T19:05:23.031785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ],
   "id": "3c71d54dd983012e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cbarril/dev/posgrado/vpc2_19co2025/vpc2/bin/python\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-26T19:05:24.697736Z",
     "start_time": "2025-07-26T19:05:24.684808Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchsummary\n",
    "import torchmetrics\n",
    "import cv2 as cv\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.maps import species_es_map, disease_es_map"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T19:05:36.398515Z",
     "start_time": "2025-07-26T19:05:35.257462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Definir carpeta 'color'\n",
    "base_dir = '../data/plantvillage/plantvillage dataset'\n",
    "sub = 'color'\n",
    "sub_path = os.path.join(base_dir, sub)\n",
    "\n",
    "data = []\n",
    "\n",
    "if os.path.exists(sub_path):\n",
    "    for folder in os.listdir(sub_path):\n",
    "        folder_path = os.path.join(sub_path, folder)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "        species, disease = folder.split('___', 1)\n",
    "        healthy = disease == 'healthy'\n",
    "        disease = None if healthy else disease\n",
    "        for file in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            if os.path.isfile(file_path):\n",
    "                data.append({\n",
    "                    'Format': sub,\n",
    "                    'Species': species,\n",
    "                    'Healthy': healthy,\n",
    "                    'Disease': disease,\n",
    "                    'FileName': file\n",
    "                })\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Agregar nombre en español para especie\n",
    "df['Especie'] = df['Species'].map(species_es_map)\n",
    "\n",
    "# Agregar nombre en español para enfermedad (o 'Sano' si es healthy)\n",
    "df['Enfermedad'] = df.apply(\n",
    "    lambda row: 'Sano' if row['Healthy'] else disease_es_map.get(row['Disease'], row['Disease']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df.head()"
   ],
   "id": "2895bdad0ade82c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Format     Species  Healthy Disease  \\\n",
       "0  color  Strawberry     True    None   \n",
       "1  color  Strawberry     True    None   \n",
       "2  color  Strawberry     True    None   \n",
       "3  color  Strawberry     True    None   \n",
       "4  color  Strawberry     True    None   \n",
       "\n",
       "                                            FileName Especie Enfermedad  \n",
       "0  8f558908-aa1b-4a86-855a-5094c2392e5a___RS_HL 1...   Fresa       Sano  \n",
       "1  b8e9ed27-8e37-4214-9206-f8c0ef21cf4d___RS_HL 4...   Fresa       Sano  \n",
       "2  abdd34a0-ab02-41e0-95a3-a014ab863ec2___RS_HL 1...   Fresa       Sano  \n",
       "3  d1aee44a-b6bb-45b9-b7b6-5d553add8fd1___RS_HL 2...   Fresa       Sano  \n",
       "4  3d28c3ea-8419-4e09-addd-211e3828e39f___RS_HL 1...   Fresa       Sano  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Format</th>\n",
       "      <th>Species</th>\n",
       "      <th>Healthy</th>\n",
       "      <th>Disease</th>\n",
       "      <th>FileName</th>\n",
       "      <th>Especie</th>\n",
       "      <th>Enfermedad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>color</td>\n",
       "      <td>Strawberry</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>8f558908-aa1b-4a86-855a-5094c2392e5a___RS_HL 1...</td>\n",
       "      <td>Fresa</td>\n",
       "      <td>Sano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>color</td>\n",
       "      <td>Strawberry</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>b8e9ed27-8e37-4214-9206-f8c0ef21cf4d___RS_HL 4...</td>\n",
       "      <td>Fresa</td>\n",
       "      <td>Sano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>color</td>\n",
       "      <td>Strawberry</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>abdd34a0-ab02-41e0-95a3-a014ab863ec2___RS_HL 1...</td>\n",
       "      <td>Fresa</td>\n",
       "      <td>Sano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>color</td>\n",
       "      <td>Strawberry</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>d1aee44a-b6bb-45b9-b7b6-5d553add8fd1___RS_HL 2...</td>\n",
       "      <td>Fresa</td>\n",
       "      <td>Sano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>color</td>\n",
       "      <td>Strawberry</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>3d28c3ea-8419-4e09-addd-211e3828e39f___RS_HL 1...</td>\n",
       "      <td>Fresa</td>\n",
       "      <td>Sano</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T19:05:39.278987Z",
     "start_time": "2025-07-26T19:05:39.226378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2 as cv\n",
    "import random\n",
    "\n",
    "# Sample a few images from the DataFrame\n",
    "sample_images = df.sample(5, random_state=42)\n",
    "\n",
    "for _, row in sample_images.iterrows():\n",
    "    folder = f\"{row['Species']}___{'healthy' if row['Healthy'] else row['Disease']}\"\n",
    "    image_path = os.path.join(base_dir, 'color', folder, row['FileName'])\n",
    "\n",
    "    img = cv.imread(image_path)\n",
    "    height, width = img.shape[:2]\n",
    "    print(f\"Image: {row['FileName']}\")\n",
    "    print(f\"Original dimensions: {width}x{height}\")\n",
    "    print(\"-\" * 40)"
   ],
   "id": "c924175a74def849",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: fe9abcc5-51b6-4524-bc31-e56e1683df72___RS_HL 7007.JPG\n",
      "Original dimensions: 256x256\n",
      "----------------------------------------\n",
      "Image: e7b889f3-d580-426e-83fb-6519f43935ef___Com.G_SpM_FL 8690.JPG\n",
      "Original dimensions: 256x256\n",
      "----------------------------------------\n",
      "Image: 7cf98788-6726-455c-9b6b-0163e80d4c0d___GCREC_Bact.Sp 3733.JPG\n",
      "Original dimensions: 256x256\n",
      "----------------------------------------\n",
      "Image: bb649ab8-c07f-4d62-a186-e2cc4963dd6b___Matt.S_CG 2652.JPG\n",
      "Original dimensions: 256x256\n",
      "----------------------------------------\n",
      "Image: d6cfcd4a-00f3-475b-9e65-0df8b7afbe25___FAM_B.Rot 3132.JPG\n",
      "Original dimensions: 256x256\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T23:08:03.117053Z",
     "start_time": "2025-07-24T23:08:03.107206Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "668915a4e1a21db0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Format     Species  Healthy Disease  \\\n",
       "0      color  Strawberry     True    None   \n",
       "1      color  Strawberry     True    None   \n",
       "2      color  Strawberry     True    None   \n",
       "3      color  Strawberry     True    None   \n",
       "4      color  Strawberry     True    None   \n",
       "...      ...         ...      ...     ...   \n",
       "54300  color     Soybean     True    None   \n",
       "54301  color     Soybean     True    None   \n",
       "54302  color     Soybean     True    None   \n",
       "54303  color     Soybean     True    None   \n",
       "54304  color     Soybean     True    None   \n",
       "\n",
       "                                                FileName Especie Enfermedad  \n",
       "0      8f558908-aa1b-4a86-855a-5094c2392e5a___RS_HL 1...   Fresa       Sano  \n",
       "1      b8e9ed27-8e37-4214-9206-f8c0ef21cf4d___RS_HL 4...   Fresa       Sano  \n",
       "2      abdd34a0-ab02-41e0-95a3-a014ab863ec2___RS_HL 1...   Fresa       Sano  \n",
       "3      d1aee44a-b6bb-45b9-b7b6-5d553add8fd1___RS_HL 2...   Fresa       Sano  \n",
       "4      3d28c3ea-8419-4e09-addd-211e3828e39f___RS_HL 1...   Fresa       Sano  \n",
       "...                                                  ...     ...        ...  \n",
       "54300  57c18b39-2a33-471f-91eb-a9ba4ddabc7b___RS_HL 6...    Soja       Sano  \n",
       "54301  4fdc663e-a8ea-4d8a-801b-ef18ad192661___RS_HL 6...    Soja       Sano  \n",
       "54302  df807f13-078b-4a6a-9c23-e43e540ecdc2___RS_HL 5...    Soja       Sano  \n",
       "54303  60bf9858-951a-4b56-906e-3c1b336973ba___RS_HL 4...    Soja       Sano  \n",
       "54304  c7f4b7b2-b13c-476e-a936-c91ce39749a3___RS_HL 6...    Soja       Sano  \n",
       "\n",
       "[54305 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Format</th>\n",
       "      <th>Species</th>\n",
       "      <th>Healthy</th>\n",
       "      <th>Disease</th>\n",
       "      <th>FileName</th>\n",
       "      <th>Especie</th>\n",
       "      <th>Enfermedad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>color</td>\n",
       "      <td>Strawberry</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>8f558908-aa1b-4a86-855a-5094c2392e5a___RS_HL 1...</td>\n",
       "      <td>Fresa</td>\n",
       "      <td>Sano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>color</td>\n",
       "      <td>Strawberry</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>b8e9ed27-8e37-4214-9206-f8c0ef21cf4d___RS_HL 4...</td>\n",
       "      <td>Fresa</td>\n",
       "      <td>Sano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>color</td>\n",
       "      <td>Strawberry</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>abdd34a0-ab02-41e0-95a3-a014ab863ec2___RS_HL 1...</td>\n",
       "      <td>Fresa</td>\n",
       "      <td>Sano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>color</td>\n",
       "      <td>Strawberry</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>d1aee44a-b6bb-45b9-b7b6-5d553add8fd1___RS_HL 2...</td>\n",
       "      <td>Fresa</td>\n",
       "      <td>Sano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>color</td>\n",
       "      <td>Strawberry</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>3d28c3ea-8419-4e09-addd-211e3828e39f___RS_HL 1...</td>\n",
       "      <td>Fresa</td>\n",
       "      <td>Sano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54300</th>\n",
       "      <td>color</td>\n",
       "      <td>Soybean</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>57c18b39-2a33-471f-91eb-a9ba4ddabc7b___RS_HL 6...</td>\n",
       "      <td>Soja</td>\n",
       "      <td>Sano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54301</th>\n",
       "      <td>color</td>\n",
       "      <td>Soybean</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>4fdc663e-a8ea-4d8a-801b-ef18ad192661___RS_HL 6...</td>\n",
       "      <td>Soja</td>\n",
       "      <td>Sano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54302</th>\n",
       "      <td>color</td>\n",
       "      <td>Soybean</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>df807f13-078b-4a6a-9c23-e43e540ecdc2___RS_HL 5...</td>\n",
       "      <td>Soja</td>\n",
       "      <td>Sano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54303</th>\n",
       "      <td>color</td>\n",
       "      <td>Soybean</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>60bf9858-951a-4b56-906e-3c1b336973ba___RS_HL 4...</td>\n",
       "      <td>Soja</td>\n",
       "      <td>Sano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54304</th>\n",
       "      <td>color</td>\n",
       "      <td>Soybean</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>c7f4b7b2-b13c-476e-a936-c91ce39749a3___RS_HL 6...</td>\n",
       "      <td>Soja</td>\n",
       "      <td>Sano</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54305 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Especie + Enfermedad como etiqueta",
   "id": "3dd3978518a2ce73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# df['Label'] = df['Especie'] + ' - ' + df['Enfermedad']\n",
    "# df['Label_id'] = df['Label'].astype('category').cat.codes\n",
    "# label_map = dict(enumerate(df['Label'].astype('category').cat.categories))\n",
    "# NUM_CLASSES = len(label_map)"
   ],
   "id": "d1001d858a103fcd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Solo Enfermedad como etiqueta",
   "id": "4b6160fd747f8a29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T23:33:32.842838Z",
     "start_time": "2025-07-24T23:33:32.825821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['Label'] = df['Enfermedad']\n",
    "df['Label_id'] = df['Label'].astype('category').cat.codes\n",
    "label_map = dict(enumerate(df['Label'].astype('category').cat.categories))\n",
    "NUM_CLASSES = len(label_map)"
   ],
   "id": "ae150e783626c3cf",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T23:33:52.729655Z",
     "start_time": "2025-07-24T23:33:52.684243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Semilla reproducible\n",
    "SEED = 42\n",
    "\n",
    "# Split 70% train, 20% valid, 10% test\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['Label_id'], random_state=SEED)\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=1/3, stratify=temp_df['Label_id'], random_state=SEED)"
   ],
   "id": "11cfbf4cb279479d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T23:44:39.133296Z",
     "start_time": "2025-07-24T23:44:39.114964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PlantVillageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, root_dir, format_type='color', transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.root_dir = root_dir\n",
    "        self.format_type = format_type\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        folder = f\"{row['Species']}___{'healthy' if row['Healthy'] else row['Disease']}\"\n",
    "        image_path = os.path.join(self.root_dir, folder, row['FileName'])\n",
    "\n",
    "        image = cv.imread(image_path)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "        # Convert BGR (OpenCV default) to RGB\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "        # Convert to PIL-like tensor manually if transforms require it\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0  # From HWC to CHW and normalize\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.df.iloc[idx]['Label_id']  # Esto puede ser int o np.int64\n",
    "        label = torch.tensor(label, dtype=torch.long)  # <-- Convierte explícitamente\n",
    "        return image, label"
   ],
   "id": "963d1dd79ebb3f44",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T23:55:17.087734Z",
     "start_time": "2025-07-24T23:44:41.436351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "from tqdm import tqdm  # para barra de progreso (opcional)\n",
    "\n",
    "def train(model, optimizer, criterion, metric, data, epochs, tb_writer=None, log_interval=10):\n",
    "    train_loader = data[\"train\"]\n",
    "    valid_loader = data[\"valid\"]\n",
    "\n",
    "    train_writer = tb_writer[\"train\"] if tb_writer else None\n",
    "    valid_writer = tb_writer[\"valid\"] if tb_writer else None\n",
    "\n",
    "    if tb_writer:\n",
    "        dummy_input = torch.zeros((1, 3, data[\"image_width\"], data[\"image_height\"]))\n",
    "        train_writer.add_graph(model, dummy_input)\n",
    "        valid_writer.add_graph(model, dummy_input)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    metric.to(device)\n",
    "\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    valid_loss = []\n",
    "    valid_acc = []\n",
    "\n",
    "    print(f\"Training started on device: {device}\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_epoch_time = time.time()\n",
    "        model.train()\n",
    "\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_train_accuracy = 0.0\n",
    "\n",
    "        # Usamos tqdm para barra de progreso en batches\n",
    "        progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{epochs} [Training]\")\n",
    "\n",
    "        for batch_idx, (train_data, train_target) in progress_bar:\n",
    "            train_data = train_data.to(device)\n",
    "            train_target = train_target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_data.float())\n",
    "            loss = criterion(output, train_target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc = metric(output, train_target)\n",
    "\n",
    "            epoch_train_loss += loss.item()\n",
    "            epoch_train_accuracy += acc.item()\n",
    "\n",
    "            if batch_idx % log_interval == 0:\n",
    "                avg_loss = epoch_train_loss / (batch_idx + 1)\n",
    "                avg_acc = epoch_train_accuracy / (batch_idx + 1)\n",
    "                progress_bar.set_postfix(loss=f\"{avg_loss:.4f}\", acc=f\"{avg_acc:.4f}\")\n",
    "\n",
    "        epoch_train_loss /= len(train_loader)\n",
    "        epoch_train_accuracy /= len(train_loader)\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        train_acc.append(epoch_train_accuracy)\n",
    "\n",
    "        # Validación\n",
    "        model.eval()\n",
    "        epoch_valid_loss = 0.0\n",
    "        epoch_valid_accuracy = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for valid_data, valid_target in valid_loader:\n",
    "                valid_data = valid_data.to(device)\n",
    "                valid_target = valid_target.to(device)\n",
    "\n",
    "                output = model(valid_data.float())\n",
    "                loss = criterion(output, valid_target)\n",
    "                acc = metric(output, valid_target)\n",
    "\n",
    "                epoch_valid_loss += loss.item()\n",
    "                epoch_valid_accuracy += acc.item()\n",
    "\n",
    "        epoch_valid_loss /= len(valid_loader)\n",
    "        epoch_valid_accuracy /= len(valid_loader)\n",
    "        valid_loss.append(epoch_valid_loss)\n",
    "        valid_acc.append(epoch_valid_accuracy)\n",
    "\n",
    "        epoch_duration = time.time() - start_epoch_time\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} completed in {epoch_duration:.1f}s - \"\n",
    "              f\"Train Loss: {epoch_train_loss:.6f}, Train Acc: {epoch_train_accuracy:.6f} - \"\n",
    "              f\"Valid Loss: {epoch_valid_loss:.6f}, Valid Acc: {epoch_valid_accuracy:.6f}\")\n",
    "\n",
    "        if tb_writer:\n",
    "            train_writer.add_scalar(\"loss\", epoch_train_loss, epoch)\n",
    "            valid_writer.add_scalar(\"loss\", epoch_valid_loss, epoch)\n",
    "            train_writer.add_scalar(\"accuracy\", epoch_train_accuracy, epoch)\n",
    "            valid_writer.add_scalar(\"accuracy\", epoch_valid_accuracy, epoch)\n",
    "            train_writer.flush()\n",
    "            valid_writer.flush()\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"valid_loss\": valid_loss,\n",
    "        \"valid_acc\": valid_acc\n",
    "    }\n",
    "\n",
    "    return history"
   ],
   "id": "7769d51658fd9818",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T23:55:17.096155Z",
     "start_time": "2025-07-24T23:44:45.778701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomResizedCrop(size=(256, 256), scale=(0.8, 1.0)),\n",
    "    # No ToTensor or Normalize needed — already applied\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "base_dir = '../data/plantvillage/plantvillage dataset'\n",
    "\n",
    "train_dataset = PlantVillageDataset(train_df, base_dir, format_type='color', transform=train_transform)\n",
    "valid_dataset = PlantVillageDataset(valid_df, base_dir, format_type='color', transform=val_test_transform)\n",
    "test_dataset = PlantVillageDataset(test_df, base_dir, format_type='color', transform=val_test_transform)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ],
   "id": "b91d5f4734364053",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T23:55:17.098737Z",
     "start_time": "2025-07-24T23:44:50.902737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resnet_model = models.resnet18(weights=None)\n",
    "resnet_model.fc = torch.nn.Linear(resnet_model.fc.in_features, NUM_CLASSES)"
   ],
   "id": "8f63dbc631154b2b",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T00:54:28.596912Z",
     "start_time": "2025-07-24T23:55:26.237085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = torch.optim.Adam(resnet_model.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "metric = torchmetrics.Accuracy(task='multiclass', num_classes=NUM_CLASSES)\n",
    "\n",
    "data_dict = {\n",
    "    \"train\": train_loader,\n",
    "    \"valid\": valid_loader,\n",
    "    \"image_width\": IMAGE_SIZE[0],\n",
    "    \"image_height\": IMAGE_SIZE[1]\n",
    "}\n",
    "\n",
    "writer = {\n",
    "    \"train\": SummaryWriter(log_dir=\"runs/plant_train\"),\n",
    "    \"valid\": SummaryWriter(log_dir=\"runs/plant_valid\")\n",
    "}\n",
    "\n",
    "history = train(\n",
    "    model=resnet_model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    metric=metric,\n",
    "    data=data_dict,\n",
    "    epochs=30,\n",
    "    tb_writer=writer\n",
    ")"
   ],
   "id": "e06d83dc42dfccda",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[23]\u001B[39m\u001B[32m, line 17\u001B[39m\n\u001B[32m      5\u001B[39m data_dict = {\n\u001B[32m      6\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mtrain\u001B[39m\u001B[33m\"\u001B[39m: train_loader,\n\u001B[32m      7\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mvalid\u001B[39m\u001B[33m\"\u001B[39m: valid_loader,\n\u001B[32m      8\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mimage_width\u001B[39m\u001B[33m\"\u001B[39m: IMAGE_SIZE[\u001B[32m0\u001B[39m],\n\u001B[32m      9\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mimage_height\u001B[39m\u001B[33m\"\u001B[39m: IMAGE_SIZE[\u001B[32m1\u001B[39m]\n\u001B[32m     10\u001B[39m }\n\u001B[32m     12\u001B[39m writer = {\n\u001B[32m     13\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mtrain\u001B[39m\u001B[33m\"\u001B[39m: SummaryWriter(log_dir=\u001B[33m\"\u001B[39m\u001B[33mruns/plant_train\u001B[39m\u001B[33m\"\u001B[39m),\n\u001B[32m     14\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mvalid\u001B[39m\u001B[33m\"\u001B[39m: SummaryWriter(log_dir=\u001B[33m\"\u001B[39m\u001B[33mruns/plant_valid\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     15\u001B[39m }\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m history = \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     18\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresnet_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     19\u001B[39m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m=\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     20\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     21\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmetric\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     22\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdata_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     23\u001B[39m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m30\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     24\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtb_writer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwriter\u001B[49m\n\u001B[32m     25\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[19]\u001B[39m\u001B[32m, line 57\u001B[39m, in \u001B[36mtrain\u001B[39m\u001B[34m(model, optimizer, criterion, metric, data, epochs, tb_writer)\u001B[39m\n\u001B[32m     54\u001B[39m epoch_valid_loss = \u001B[32m0.0\u001B[39m\n\u001B[32m     55\u001B[39m epoch_valid_accuracy = \u001B[32m0.0\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m57\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mvalid_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_target\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mvalid_loader\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     58\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcuda\u001B[49m\u001B[43m.\u001B[49m\u001B[43mis_available\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     59\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalid_data\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcuda\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dev/posgrado/vpc2_19co2025/vpc2/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    730\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    731\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    732\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m733\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    734\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    735\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    736\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    737\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    738\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    739\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dev/posgrado/vpc2_19co2025/vpc2/lib/python3.12/site-packages/torch/utils/data/dataloader.py:789\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    787\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    788\u001B[39m     index = \u001B[38;5;28mself\u001B[39m._next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m789\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    790\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n\u001B[32m    791\u001B[39m         data = _utils.pin_memory.pin_memory(data, \u001B[38;5;28mself\u001B[39m._pin_memory_device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dev/posgrado/vpc2_19co2025/vpc2/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001B[39m, in \u001B[36m_MapDatasetFetcher.fetch\u001B[39m\u001B[34m(self, possibly_batched_index)\u001B[39m\n\u001B[32m     50\u001B[39m         data = \u001B[38;5;28mself\u001B[39m.dataset.__getitems__(possibly_batched_index)\n\u001B[32m     51\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m         data = [\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     54\u001B[39m     data = \u001B[38;5;28mself\u001B[39m.dataset[possibly_batched_index]\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[18]\u001B[39m\u001B[32m, line 27\u001B[39m, in \u001B[36mPlantVillageDataset.__getitem__\u001B[39m\u001B[34m(self, idx)\u001B[39m\n\u001B[32m     24\u001B[39m image = torch.from_numpy(image).permute(\u001B[32m2\u001B[39m, \u001B[32m0\u001B[39m, \u001B[32m1\u001B[39m).float() / \u001B[32m255.0\u001B[39m  \u001B[38;5;66;03m# From HWC to CHW and normalize\u001B[39;00m\n\u001B[32m     26\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.transform:\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m     image = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     29\u001B[39m label = \u001B[38;5;28mself\u001B[39m.df.iloc[idx][\u001B[33m'\u001B[39m\u001B[33mLabel_id\u001B[39m\u001B[33m'\u001B[39m]  \u001B[38;5;66;03m# Esto puede ser int o np.int64\u001B[39;00m\n\u001B[32m     30\u001B[39m label = torch.tensor(label, dtype=torch.long)  \u001B[38;5;66;03m# <-- Convierte explícitamente\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dev/posgrado/vpc2_19co2025/vpc2/lib/python3.12/site-packages/torchvision/transforms/transforms.py:95\u001B[39m, in \u001B[36mCompose.__call__\u001B[39m\u001B[34m(self, img)\u001B[39m\n\u001B[32m     93\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[32m     94\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.transforms:\n\u001B[32m---> \u001B[39m\u001B[32m95\u001B[39m         img = \u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     96\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dev/posgrado/vpc2_19co2025/vpc2/lib/python3.12/site-packages/torchvision/transforms/transforms.py:137\u001B[39m, in \u001B[36mToTensor.__call__\u001B[39m\u001B[34m(self, pic)\u001B[39m\n\u001B[32m    129\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, pic):\n\u001B[32m    130\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    131\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m    132\u001B[39m \u001B[33;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    135\u001B[39m \u001B[33;03m        Tensor: Converted image.\u001B[39;00m\n\u001B[32m    136\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m137\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/dev/posgrado/vpc2_19co2025/vpc2/lib/python3.12/site-packages/torchvision/transforms/functional.py:142\u001B[39m, in \u001B[36mto_tensor\u001B[39m\u001B[34m(pic)\u001B[39m\n\u001B[32m    140\u001B[39m     _log_api_usage_once(to_tensor)\n\u001B[32m    141\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (F_pil._is_pil_image(pic) \u001B[38;5;129;01mor\u001B[39;00m _is_numpy(pic)):\n\u001B[32m--> \u001B[39m\u001B[32m142\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mpic should be PIL Image or ndarray. Got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(pic)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    144\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m _is_numpy(pic) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_numpy_image(pic):\n\u001B[32m    145\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mpic should be 2/3 dimensional. Got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpic.ndim\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m dimensions.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mTypeError\u001B[39m: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "axs[0].plot(history[\"train_loss\"], label='Train Loss')\n",
    "axs[0].plot(history[\"valid_loss\"], label='Valid Loss')\n",
    "axs[0].set_title('Loss')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(history[\"train_acc\"], label='Train Accuracy')\n",
    "axs[1].plot(history[\"valid_acc\"], label='Valid Accuracy')\n",
    "axs[1].set_title('Accuracy')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "5a7b671e8acfebe3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (vpc3)",
   "language": "python",
   "name": "vpc3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
